# -*- coding: utf-8 -*-
"""Pre-Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TbJe5T1GE5PgJ2_CJKmyQsJIWJVPT5xp
"""

!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz

!tar xvzf aclImdb_v1.tar.gz

!pip install keras==2.1.0

"""# Read files into Pandas"""

import pandas as pd
import numpy as np

import os

train = []

#read in negative reviews of training set
directory = 'aclImdb/train/neg/'
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        f = open(directory+filename)
        text = f.read()
        sentiment = 0
        rating = int(filename[-5])
        train.append([text,sentiment,rating])
    else:
        continue

#read in positive reviews of training set
directory = 'aclImdb/train/pos/'
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        f = open(directory+filename)
        text = f.read()
        sentiment = 0
        rating = int(filename[-5])
        train.append([text,sentiment,rating])
    else:
        continue
      
train = pd.DataFrame(train,columns = ['text','sentiment','rating'])



      
test = []

#read in negative reviews of test set
directory = 'aclImdb/test/neg/'
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        f = open(directory+filename)
        text = f.read()
        sentiment = 0
        rating = int(filename[-5])
        test.append([text,sentiment,rating])
    else:
        continue

#read in positive reviews of test set
directory = 'aclImdb/test/pos/'
for filename in os.listdir(directory):
    if filename.endswith(".txt"):
        f = open(directory+filename)
        text = f.read()
        sentiment = 0
        rating = int(filename[-5])
        test.append([text,sentiment,rating])
    else:
        continue
        
        
test = pd.DataFrame(test,columns = ['text','sentiment','rating'])

train = train.sample(frac=1).reset_index(drop=True)
test = test.sample(frac=1).reset_index(drop=True)
train.to_csv('files/train.csv')
test.to_csv('files/test.csv')

"""# Word2Vec - Get Vocabulary"""

from string import punctuation
from os import listdir
from collections import Counter

 
# load file into memory
def load_doc(filename):
  import string
  file = open(filename, 'rt')
  text = file.read()
  file.close()
  #split at whitespace
  words = text.split()
  # remove punctuation from each word
  table = str.maketrans('', '', string.punctuation)
  stripped = [w.translate(table) for w in words]
  return stripped
 

# load doc and add to vocab
def add_doc_to_vocab(filename, vocab):
	# load doc
	doc = load_doc(filename)
	# clean doc
	tokens = clean_doc(doc)
	# update counts
	vocab.update(tokens)
  

# load all docs in a directory
def process_docs(directory, vocab):
	# walk through all files in the folder
  for filename in listdir(directory):
    path = directory + '/' + filename
    file_tokens = load_doc(path)
    vocab.update(file_tokens)

	
# save list to file
def save_vocab_as_list(lines, filename):
	data = '\n'.join(lines)
	file = open(filename, 'w')
	file.write(data)
	file.close()

    
# define vocab
vocab = Counter()
# add all docs to vocab
process_docs('aclImdb/test/neg/', vocab)
process_docs('aclImdb/test/pos/', vocab)
process_docs('aclImdb/train/neg/', vocab)
process_docs('aclImdb/train/pos/', vocab)

#keep only vocab with minimum occurence
min_occurance = 3
vocab = [k for k,c in vocab.items() if c >= min_occurance]
vocab = [word.lower() for word in vocab]

vocab = set(vocab)
print(len(vocab))

save_vocab_as_list(vocab, 'files/vocab.txt')

